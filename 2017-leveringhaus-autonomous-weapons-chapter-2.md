% Leveringhaus: Ethics and Autonomous Weapons - Chapter 2
% Alexandra Haas | Michael Czechowski
% Seminar: Prof. Dr. Catrin Misslhorn - Kriegsroboter, Drohnen und Co. - Zur Ethik autonomer Waffensysteme (WiSe 2017/18)
---
  papersize: a4paper
  geometry: left=4cm
  geometry: top=2.5cm
  fontsize: 12pt
  toc: no
  lang: de
...

## Wichtigkeit des Designs

### Was ist eine Waffe?

- Der Unterschied zwischen Waffen und anderen Artefakten liegt in Ihrem jeweiligen Design und dessen darin liegende Intention. 
- Im Design einer Waffe liegt die Intention Schaden oder Verletzungen anzurichten. 
  *Eine nicht verletzende Waffe ist ein Wiederspruch in sich.*

### Problem der militärischen „Support-Systems“ und die Möglichkeit moralischer Rechtfertigung in Bezug auf die "Doctrine of Double-Effect":

- Die Doktrin besagt, dass es konzeptuell und normativ notwendig ist, zwischen dem zu unterscheiden, was ein Akteur beabsichtigt und was ein Akteur vorhersieht.
- Annahme der Waffenbefürworter: Die primäre Intention von Radarsystemen liegt nicht darin Schaden anzurichten, kann aber durch einen Nebeneffekt zu Schaden führen. Bsp.: Man wollte das Land beschützen und konnte nicht wirklich vorhersehen, dass dabei Unmengen von Zivilisten getötet wurden. 

 ### Leveringhaus‘ Gegenargument:

Sein Gegenargument basiert auf der primären Komponente beim Design einer Waffe, nämlich, dass sie fähig sein muss Schaden anzurichten, und das ist auch bei Supportsystemen der Fall. 

## Verletzung und Schaden als zetrales Element

### Leveringhaus‘ Definition von Schädigung/Verletzung richtet sich nach Joel Feinberg:

Schaden oder Verletzung im unmoralischen Sinn wird über zwei Komponenten definiert: 

1.	Meine schädigende/verletzende Handlung durch eine Waffe bedeutet einen Rückschlag der Interessen einer anderen Person.
2.	Meine schädigende/verletzende Handlung durch eine Waffe zieht eine Rechtsverletzung der geschädigten Person nach sich. (Bsp.: Recht auf Privatsphäre)

### Unterscheidung zwischen dreierlei Arten von Waffen:

1.	Waffen die keine tödlichen oder damit in Beziehung stehenden Verletzungen anrichten: Bsp. Eine Computersoftware richtet zwar einen Schaden an, dieser ist aber nicht tödlich und führt auch zu einem späteren Zeitpunkt nicht zum Tod.
2.	Waffen, die tödlichen oder damit in Beziehung stehende Verletzungen als Nebeneffekt anrichten. Bsp.: Truppe A blockiert das Radarsystem von Truppe B.
3.	Waffen, deren primäre Funktion es ist, tödlichen oder einen damit in Beziehung stehenden Schaden anzurichten. Bsp.: Maschinengewehr.

Der 2. & 3. Punkt sind wesentlich für die Diskussion um autonome Waffen.

### Leverings Antwort auf Einwände:

#### 1.	Einwand gliedert sich in zwei Komponenten: 
1a) Geht der Schaden im Sinne Feinbergs wirklich nur vom Design aus oder von der Handlung eingebettet in einen gerechten oder ungerechten Krieg?

1b) Bezüglich einer ungerechten Handlung ist es fraglich, ob das Zerstören einer beispielsweise Rakete eine Verletzung der Rechte von Personen darstellt. 

#### Leveringhaus‘ Antwort: 
Wenn „nur“ militärische Artefakte, wie etwa Raketen oder Tanklaster beschädigt werden, kann man trotzdem von einer Rechtsverletzung von Menschen sprechen, weil diese als Steuerzahler die militärischen Artefakte finanzieren.

#### 2.	Einwand: 
Unterscheidung von offensiven und defensiven Waffen fordert eine Unterscheidung zwischen offensiver und defensiver Schädigung, beziehungsweise Verletzung. 

#### Leveringhaus‘ Antwort: 
Für ethische Fragen ist mit dieser Unterscheidung nichts gewonnen. Auch defensive Waffen sind moralisch problematisch, weil sie a. die Fähigkeit der Gegner unterminieren sich verteidigen zu können und b. missbraucht werden können um einen ungerechten Krieg zu initiieren. 


### Doctrine of Double Effect

### Waffendesign beinhaltet Leid und Schaden

## Feinberg: Was sind Leid und Schaden

## Autonomiebegriff

 - Mensch: "In a nutshell, the concept of autonomy denotes that an agent acts for reasons the agent has given him/herself." [S. 47]
 - Maschine: 

## Autonomie einer Maschine und Waffentechnolgie

### Inhaltlicher Aufbau

- Was ist Autonomie? (ab S. 46)
- Was ist Unabhängigkeit (ab S. 48)
- Drohnen und unbewohnte Maschinen bzw. Waffen (ab S. 49 oben)
- "In/on/out-of - the - Loop" (ab S. 49 unten)
- Was sind Kognitive Systeme und Künstliche Agenten? (ab S. 50)
- Was unterscheidet autonome Waffen von Unterstützungssystemen? (ab S. 52)
- Zielerfassung (ab S. 53)
  - Das "Generating Model" (ab S. 53 unten)
  - Das "Execution Model" (ab S. 56)
- Zusammenfassung (ab S. 57) 

### Argumente

(1) Wenn eine Maschine das Design bzw. den Zweck hat Leid und Schaden zuzufügen, handelt es sich um eine Waffe.
(2) Die Entwicklung von Waffen steht unter bestimmten rechtlichen sowie moralischen Regulierungen.
(3) Es wird angenommen, dass alle vorherschenden Waffensysteme in Benutzung unter einer moralischen und rechtlichen Regulierung stehen.
(4) Wenn autonome Waffen nicht zu den Konzepten der bestehenden Waffensystemen passen und in ihrer Beispiellosigkeit über diese hinausgehen, dann gilt es neue Regulierungen und Debatten zur moralischen Zulässigkeit dieser neuen Waffensysteme zu erarbeiten.
(5) Ein Agent handelt im philosophischen Sinne dann und nur dann autonom, wenn er aus eigens gewählten Gründen handelt.
(6) Maschinen werden programmiert, gesteuert und oder von einem externen menschlichen Agente überwacht.
(5) + (6) Maschinen sind in jeder Weise vom Menschen fremdbestimmt und können daher nicht qua philosophischer Autonomie handeln. Immer wohnen Absichten von anderen Handlungsträgen bei der Entscheidungsfindung einer Maschine bei.

1. Waffen haben ein Design
2. Ihr Zweck ist Leid und Schaden

*Sind autonome Waffen ein beispielloses und einzigartiges Phänomen in der Waffentechnologie?*

- Wenn ja, dann gilt es die bestehenden Regulierungen und den moralischen Rahmen neu zu setzen.
- Wenn nein, dann reichen die bisherigen Regulierungen aus. 

